# -*- coding: utf-8 -*-
"""ML_HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mgv2oMt9SDqUKFbbsZ3YpX2C2NJ2METC
"""

from google.colab import drive
drive.mount('/content/gdrive')

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
from sklearn.linear_model import LinearRegression, Ridge, Lasso 
from sklearn.model_selection import train_test_split, cross_val_score 
from statistics import mean

trdata= pd.read_csv("/content/gdrive/My Drive/ML/HW2/trainData.csv")
trlabel = pd.read_csv("/content/gdrive/My Drive/ML/HW2/trainLabels.csv")
valdata = pd.read_csv("/content/gdrive/My Drive/ML/HW2/valData.csv")
vallabel = pd.read_csv("/content/gdrive/My Drive/ML/HW2/valLabels.csv")
testlabel = pd.read_csv("/content/gdrive/My Drive/ML/HW2/testData_new.csv")

feature = pd.read_csv("/content/gdrive/My Drive/ML/HW2/features.csv")

trdata.shape

testlabel.shape

trdata = trdata.iloc[:,1:]
trlabel = trlabel.iloc[:,1:]
valdata = valdata.iloc[:,1:]
vallabel = vallabel.iloc[:,1:]
testlabel = testlabel.iloc[:,1:]
inputX = np.transpose(trdata.values) 
output = trlabel.values
wvalues_ridge = []

testlabel.shape

def Ridge1(X,Y,Lambda):
  (k,N) = X.shape
  X2 = np.ones((1,N))
  Xbar = np.vstack((X,X2))
  Xbartran = np.transpose(Xbar)
  Product = Xbar.dot(Xbartran)
  Identity = np.identity(k)
  #print(Identity)
  X0 = np.zeros((k,1))
  X1 = np.zeros((1,k+1))
  IdenHor = np.hstack((Identity,X0))
  IdenVer = np.vstack((IdenHor, X1))
  Mul = np.dot(IdenVer,Lambda)
  Num = np.add(Mul,Product)
  Denom  = np.dot(Xbar,Y)    
  Inve = np.linalg.inv(Num)
  #print('Ridge')
  Final = np.dot(Inve,Denom)
  #print('\n')
  #print('The scalar b value')
  b = Final[-1]
  #print('\n')
  #print(b)
  Wval = Final[:-1]
  #print(Wval)
  wtran = np.transpose(Wval)
  sum1=0
  for i in range(0,N):
    o=X[...,i].ravel()
    otr= np.transpose(o)
    prod= 0
    prod = wtran.dot(otr)
    sum1 = sum1 + prod
  caly= sum1+b[0]
  pred = (caly - Y[i])**2
  WFinal = np.sum(np.array(Wval)**2)*Lambda
  obj = WFinal + pred
  Errori=[]
  for i in range(N):
    numerator=  np.transpose(Final).dot(Xbar[...,i].ravel()) - Y[i][0]
    sam= np.transpose(Xbar[...,i].ravel()).dot(Inve)
    sample = sam.dot(Xbar[...,i].ravel())
    denominator = 1 -sample
    Errori.append(numerator/denominator)
   
  return [Wval,b,obj,Errori]

r1=Ridge1(inputX,output,1)
Ridge_Model_Coefficient=r1[0]
Ridge_Model_bvalue=r1[1]
Ridge_Model_obj = r1[2]
Ridge_Model_Error = r1[3]
Ridge_Model_Coefficient

Ridge_Model_bvalue

Ridge_Model_obj

Ridge_Model_Error

GenerateVal=[]
for i in range(0,4748):
  PredictionVal=testlabel.values[i].dot(Ridge_Model_Coefficient)+ Ridge_Model_bvalue
  GenerateVal.append(PredictionVal[0])
GenerateVal

mean1 = np.mean(GenerateVal)
mean1

len(GenerateVal)

RmsVal=[]
for i in range(0,4748):
  RmsVal.append((GenerateVal[i]-vallabel.values[i])**2)
  
rms_value=np.sqrt(np.mean(RmsVal))
rms_value

arrr = []
arrr1 = []
outer_arr = []
for i in [0.01, 0.1, 1, 10, 100, 1000]:
  r1=Ridge1(inputX,output,i)
  Ridge_Model_Coefficient=r1[0]
  Ridge_Model_bvalue=r1[1]
  Ridge_Model_obj = r1[2]
  Ridge_Model_Error = r1[3]
  Ridge_Model_Coefficient
  GenerateVal=[]
  for k in range(0,4999):
    PredictionVal=valdata.values[k].dot(Ridge_Model_Coefficient)+ Ridge_Model_bvalue
    GenerateVal.append(PredictionVal[0])
  RmsVal=[]
  for j in range(0,4999):
    RmsVal.append((GenerateVal[j]-vallabel.values[j])**2)
  arrr.append(np.sqrt(np.mean(RmsVal)))
  locerr = []
  for t in range(len(Ridge_Model_Error)):
    locerr.append((Ridge_Model_Error[t])**2)
  outer_arr.append(np.sqrt(np.mean(locerr)))
  Generate = []
  for k in range(0,4999):
    Prediction=trdata.values[k].dot(Ridge_Model_Coefficient)+ Ridge_Model_bvalue
    Generate.append(Prediction[0])
  Rms=[]
  for j in range(0,4999):
    Rms.append((Generate[j]-trlabel.values[j])**2)
  arrr1.append(np.sqrt(np.mean(Rms)))
    
arrr

r = np.square(arrr1)
sum1 = np.sum(r)
sum1

rmstrain = []
arrr1 = []
outer_arr = []
Generate=[]
sum11=0
for k in range(0,4999):
  Prediction=trdata.values[k].dot(Ridge_Model_Coefficient)+ Ridge_Model_bvalue
  Generate.append(Prediction[0])
Rms=[]
for j in range(0,4999):
  sum11=sum11+(Generate[j]-trlabel.values[j])**2
sum11

fig,graph=plt.subplots()
value = [0.01, 0.1, 1, 10, 100,1000]
graph.plot(value, arrr,'r', value, arrr1,'b', value, outer_arr,'g')
graph.set_xlabel("Lambda values")
graph.set_ylabel("RMS values - Validation, Training, LOOCV")
graph.legend(labels=['Validation data','Train Data','LOOCV Data'])
graph.set_title("RMS Values Plot")

fig, graph=plt.subplots()
graph.plot([0.01, 0.1, 1, 10, 100, 1000],arrr,'r')
graph.set_xlabel("Lambda")
graph.set_ylabel("RMS")
graph.set_title("Lambda vs RMS")

df = pd.DataFrame(y)  
# saving the dataframe 
df.to_csv('reg.csv', header=False, index=False) 
y.shape

ze= feature.join(trlabel)
ze

tu = tr.corr()
z = tu["85"]
absolu = abs(z)

sor = abs(z)
e = pd.DataFrame(sor)
e.shape
sor1 = e.sort_values(e.columns[0])
sor1

value1 = pd.DataFrame(trdata.columns).join(feature)

value1.to_csv('ze.csv', header=False, index=False)